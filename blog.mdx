# Building a Netflix Web Show Recommender with Crawlee

Scraping data from websites Netflix is not as easy as scraping data from any regular website. Netflix website heavily depends on JavaScript and it consists tons of elements. But Crawlee makes it super easy to scrape such complex websites.

[Crawlee](https://crawlee.dev/), a web scraping and browser automation library, helps us crawl websites, scrape data from them, and store the scraped data at the defined location.

Crawlee's features—autoscaling, proxy rotation, persistent URL queue, headless browser support, and Docker compatibility—make website scraping super easy.

In this blog, we will use Crawlee to scrape data from the Netflix website and use the scraped data to build a Netflix Web Show Recommender project.

We will set up Crawlee and understand how it works. Let’s get started.

## Prerequisites

To use Crawlee, you need to have Node.js 16 or higher version.

You can install the latest version of Nodejs from their [official website](https://nodejs.org/en/).

## Creating the project

To build the Web Show Recommender project, we will scrape data from the Netflix website, save it, and use it to build the project.

### Creating React app

Firstly, we will create a React app using Vite. You can check out the [ReactJS Docs](https://react.dev/) to create a React app.

Once the React app is created, open it in VS Code.

[img](assets/1.png)

This will be the structure of your React app.

Run `npm run dev` command in the terminal to run the app.

This will be the output displayed by the React app.

### Adding Scraper code

Now, we will integrate Crawlee into our project and scrape the Netflix data using it.

As per our project requirements, we will scrape the genres and the titles of the shows available on Netflix.

Let’s start building the scraper code.

##### Installation

We have to install two libraries - `crawlee` and `playwright`. Run this command to install these libraries:

```
npm install crawlee playwright
```

[Crawlee](https://crawlee.dev/) is a web scraping and browser automation library. It helps to build crawlers to scrape the data from websites.

[Playwright](https://github.com/microsoft/playwright) is a framework for Web Testing and Automation. It allows testing Chromium, Firefox, and WebKit with a single API. Created by Microsoft.

Crawlee, built on Playwright, empowers headless browser scraping for complex websites. While slower and more resource-intensive, it tackles intricate JavaScript-heavy scenarios that basic crawlers can't handle.

After installing the libraries, it’s time to create the scraper code.

##### Importing libraries

PlaywrightCrawler class has been imported from the `crawlee` library. `PlaywrightCrawler` crawls the web using a headless browser controlled by the `Playwright` library.

```js
import { PlaywrightCrawler } from "crawlee";
```

#### Scraping genres

To scrape the genres, we will utilize the [browser Devtools](https://developer.mozilla.org/en-US/docs/Learn/Common_questions/Tools_and_setup/What_are_browser_developer_tools) to identify the tags and CSS selectors targeting the genre elements on the Netflix website.

Here, we can observe that the name of the genre is captured by the _span_ tag having _nm-collections-row-name_ class. So we can use the _span.nm-collections-row-name_ selector to capture this and similar elements.

```js
const titles = await page.$$eval("span.nm-collections-row-name", (elements) => {
  // Map the text content of each element
  return elements.map((el) => el.textContent.trim());
});
```

This will give us the list of all the genres stored in _titles_ array.

#### Scraping shows

To scrape the show titles, we'll use the same method we used for scraping genres. Let’s find out the tag capturing the shows’ names.

Here, we can observe that the title of the show is captured by the _span_ tag having _nm-collections-title-name_ class. So we can use the _span.nm-collections-title-name_ selector to capture this and similar elements.

```js
const shows = await page.$$eval(
  "span.nm-collections-title-name",
  (elements) => {
    // Map the text content of each element
    return elements.map((el) => el.textContent.trim());
  }
);
```

This will scrape the title of all the shows and store it in the _shows_ array.

```js
let allShows = [];
let totalShows = [];
shows.map((show) => {
  if (allShows.length == 40) {
    totalShows.push(allShows);
    allShows = [];
  }
  allShows.push(show);
});
```

Here, we have performed some basic operations on the _shows_ array to get the _totalShows_ array in the desired format.

#### Storing data

Now we have every data that we want for our project and it’s time to store or save the scraped data. To store the data, crawlee comes with a **crawlee.pushData** method.

The [pushData()](https://crawlee.dev/docs/introduction/saving-data) method creates a storage folder in the project directory and stores the scraped data in the json format.

```js
await crawlee.pushData({
  genre: titles,
  shows: totalShows,
});
```

This will save the titles and totalShows arrays as values in _genre_ and _shows_ keys.

Here’s the code that we will use in our project:

```js
import { PlaywrightCrawler } from "crawlee";

const crawler = new PlaywrightCrawler({
  requestHandler: async ({ page, request, enqueueLinks, pushData }) => {
    console.log(`Processing: ${request.url}`);
    console.log(request.label);

    const titles = await page.$$eval(
      "span.nm-collections-row-name",
      (elements) => {
        // Map the text content of each element
        return elements.map((el) => el.textContent.trim());
      }
    );
    // console.log(titles);
    const shows = await page.$$eval(
      "span.nm-collections-title-name",
      (elements) => {
        // Map the text content of each element
        return elements.map((el) => el.textContent.trim());
      }
    );

    let allShows = [];
    let totalShows = [];
    shows.map((show) => {
      if (allShows.length == 40) {
        totalShows.push(allShows);
        allShows = [];
      }
      allShows.push(show);
    });

    await pushData({
      genre: titles,
      shows: totalShows,
    });
  },

  // Let's limit our crawls to make our tests shorter and safer.
  maxRequestsPerCrawl: 20,
});

await crawler.run(["https://www.netflix.com/in/browse/genre/1191605"]);
```

The `maxRequestPerCrawl` limits the crawlee to crawl only the first page of the given url to make the tests shorter and safer. You can ignore this code line to crawl the entire website.

```js
await crawler.run(["https://www.netflix.com/in/browse/genre/1191605"]);
```

In this code snippet, we have defined the url that we want to scrape data from. You can scrape multiple urls also by adding the other urls in the array.

Now we will run the crawlee to scrape the website. Before running the crawlee, we need to tweak the `package.json` file. We will add the `start` script targeting the `scrap.js` file to run the crawlee.

Add the following code in `"scripts"` object:

```
"start": "node src/scrap.js"
```

and save it. Now run this command to run the crawlee the scrape the data:

```
npm start
```

After running this command, you will see a `storage` folder having `datasets\default\000000001.json` file. In this json file, the scrapped data will be stored in json format.

Now we can use this json data and display it in the `App.jsx` component to create the project.

In the `App.jsx` component, you can see we have imported `jsonData` from the `000000001.json` file:

```js
import jsonData from "../storage/datasets/default/000000001.json";
```

Then we have used this `jsonData` and performed some `map` methods to get the desired results. Here is the full code of `App.jsx`:

```js
import { useState } from "react";
import "./App.css";
import jsonData from "../storage/datasets/default/000000001.json";

function App() {
  const [count, setCount] = useState();
  const handleChange = (event) => {
    setCount(event.target.value);
  };

  return (
    <>
      <h1>Netflix Web Show recommender</h1>
      <div>
        <select onChange={handleChange}>
          <option value="">Select your genre</option>;
          {jsonData.genre.map((genre, key) => {
            return <option value={key}>{genre}</option>;
          })}
        </select>
      </div>
      <div style={{ display: "flex" }} className="lists">
        <div style={{ flex: "50%", paddingRight: "10px", textAlign: "left" }}>
          {count &&
            jsonData.shows[count].slice(0, 20).map((show) => <li>{show}</li>)}
        </div>
        <div style={{ flex: "50%", paddingLeft: "10px", textAlign: "left" }}>
          {count &&
            jsonData.shows[count].slice(20).map((show) => <li>{show}</li>)}
        </div>
      </div>
    </>
  );
}

export default App;
```

In this code snippet, `genre` array is used to display the list of genres. User can select their desired genre and based upon that a list of web shows available on Netflix will be displayed using the `shows` array.

Now our project is ready!

## Result

Now, to run your project in the localhost, run this command:

```
npm run dev
```

This command will run your project on the localhost. Here is the demo of the project:

Project link - [https://github.com/ayush2390/web-show-recommender](https://github.com/ayush2390/web-show-recommender)

In this way, you can scrape data from any website using crawlee and create some unique projects using the scraped data.

Want to know more about Crawlee? You can watch our Crawlee guide video:

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/g1Ll9OlFwEQ?si=EMeYil29LV0oDOxc"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
  referrerpolicy="strict-origin-when-cross-origin"
  allowfullscreen
></iframe>
