# Building a Netflix Web Show Recommender with Crawlee and React

In this blog, we'll guide you through the process of using Vite and Crawlee to build a website that recommends Netflix shows based on their categories and genres. To do that, we will first scrape the shows and categories from Neflix using Crawlee, and then visualize scraped data in a React app built with Vite. By the end of this guide, you'll have a functional web show recommender that can provide Netflix show suggestions. 

Let’s get started!

## Prerequisites

To use Crawlee, you need to have Node.js 16 or higher version.

You can install the latest version of Node.js from their [official website](https://nodejs.org/en/).

## Creating React app

Firstly, we will create a React app (for frontend) using Vite. Run this command in the terminal to create react app:

```
npx create-vite@latest
```

You can check out the [Vite Docs](https://vitejs.dev/guide/) to create a React app.

Once the React app is created, open it in VS Code.

![react](assets/react.png)

This will be the structure of your React app.

Run `npm run dev` command in the terminal to run the app.

![viteandreact](assets/viteandreact.png)

This will be the output displayed by the React app.

## Adding Scraper code

As per our project requirements, we will scrape the genres and the titles of the shows available on Netflix.

Let’s start building the scraper code.

### Installation

We will install two libraries - `crawlee` and `cheerio`. Run this command to install these libraries:

```
npm install crawlee
```

Crawlee utilizes Cheerio for [HTML parsing and scraping](https://crawlee.dev/blog/scrapy-vs-crawlee#html-parsing-and-scraping) of static websites. While faster and [less resource-intensive](https://crawlee.dev/docs/guides/scaling-crawlers), it can only scrape websites that do not require JavaScript rendering, making it unsuitable for SPAs (single page applications).

Additionally, Crawlee supports headless browser libraries like [Playwright](https://playwright.dev/) and [Puppeteer](https://pptr.dev/) for scraping of websites that are JavaScript-rendered. 

After installing the libraries, it’s time to create the scraper code.

Create a file in `src` directory and name it `scraper.js`. Whole scraper code will be created in this file.

### Scraping genres and shows

To scrape the genres and shows, we will utilize the [browser DevTools](https://developer.mozilla.org/en-US/docs/Learn/Common`questions/Tools`and`setup/What`are`browser`developer`tools) to identify the tags and CSS selectors targeting the genre elements on the Netflix website.

We can capture the HTML structure and call `$(element)` to query the element's subtree.

![genre](assets/genre.png)

Here, we can observe that the name of the genre is captured by the `span` tag having `nm-collections-row-name` class. So we can use the `span.nm-collections-row-name` selector to capture this and similar elements.

![title](assets/title.png)

Similarly, we can observe that the title of the show is captured by the `span` tag having `nm-collections-title-name` class. So we can use the `span.nm-collections-title-name` selector to capture this and similar elements.

```js
// Use parseWithCheerio for efficient HTML parsing
    const $ = await parseWithCheerio();

    // Extract genre and shows directly from the HTML structure
    const data = $('[data-uia="collections-row"]')
      .map((_, el) => {
        const genre = $(el)
          .find('[data-uia="collections-row-title"]')
          .text()
          .trim();
        const items = $(el)
          .find('[data-uia="collections-title"]')
          .map((_, itemEl) => $(itemEl).text().trim())
          .get();
        return { genre, items };
      })
      .get();

    // Prepare data for pushing
    const genres = data.map((d) => d.genre);
    const shows = data.map((d) => d.items);
```

This will give the `genres` and `shows` array having list of genres and shows stored in it respectively.

### Storing data

Now we have every data that we want for our project and it’s time to store or save the scraped data. To store the data, crawlee comes with a `pushData()` method.

The [pushData()](https://crawlee.dev/docs/introduction/saving-data) method creates a storage folder in the project directory and stores the scraped data in the json format.

```js
await pushData({
      genre: genres,
      shows: shows,
    });
```  

This will save the `genres` and `shows` arrays as values in the `genre` and `shows` keys.

Here’s the full code that we will use in our project:

```js
import { CheerioCrawler, log, Dataset } from "crawlee";

const crawler = new CheerioCrawler({
  requestHandler: async ({ request, parseWithCheerio, pushData }) => {
    log.info(`Processing: ${request.url}`);

    // Use parseWithCheerio for efficient HTML parsing
    const $ = await parseWithCheerio();

    // Extract genre and shows directly from the HTML structure
    const data = $('[data-uia="collections-row"]')
      .map((_, el) => {
        const genre = $(el)
          .find('[data-uia="collections-row-title"]')
          .text()
          .trim();
        const items = $(el)
          .find('[data-uia="collections-title"]')
          .map((_, itemEl) => $(itemEl).text().trim())
          .get();
        return { genre, items };
      })
      .get();

    // Prepare data for pushing
    const genres = data.map((d) => d.genre);
    const shows = data.map((d) => d.items);

    await pushData({
      genre: genres,
      shows: shows,
    });
  },

  // Limit crawls for efficiency
  // maxRequestsPerCrawl: 20,
});

await crawler.run(["https://www.netflix.com/in/browse/genre/1191605"]);
await Dataset.exportToJSON("results");
```

Now, we will run Crawlee to scrape the website. Before running Crawlee, we need to tweak the `package.json` file. We will add the `start` script targeting the `scraper.js` file to run Crawlee.

Add the following code in `'scripts'` object:

```
'start': 'node src/scraper.js'
```

and save it. Now run this command to run the crawlee the scrape the data:

```sh
npm start
```

After running this command, you will see a `storage` folder having `key_value_stores/default/results.json` file. In this json file, the scrapped data will be stored in json format.

Now we can use this json data and display it in the `App.jsx` component to create the project.

In the `App.jsx` component, we will import `jsonData` from the `results.json` file:

```js
import jsonData from '../storage/key_value_stores/default/results.json';
```

Then we have used this `jsonData` and performed some `map` methods to get the desired results. Here is the full code of `App.jsx`:

```js
import { useState } from 'react';
import './App.css';
import jsonData from '../storage/key_value_stores/default/results.json';

function HeaderAndSelector({ handleChange }) {
  return (
    <>
      <h1 className='header'>Netflix Web Show Recommender</h1>
      <div className='genre-selector'>
        <select onChange={handleChange} className='select-genre'>
          <option value=''>Select your genre</option>
          {jsonData[0].genre.map((genre, key) => {
            return (
              <option key={key} value={key}>
                {genre}
              </option>
            );
          })}
        </select>
      </div>
    </>
  );
}

function App() {
  const [count, setCount] = useState(null);

  const handleChange = (event) => {
    const value = event.target.value;
    if (value) setCount(parseInt(value));
  };

  // Validate count to ensure it is within the bounds of the jsonData.shows array
  const isValidCount = count !== null && count <= jsonData[0].shows.length;

  return (
    <div className='app-container'>
      <HeaderAndSelector handleChange={handleChange} />
      <div className='shows-container'>
        {isValidCount && (
          <>
            <div className='shows-list'>
              <ul>
                {jsonData[0].shows[count].slice(0, 20).map((show, index) => (
                  <li key={index} className='show-item'>
                    {show}
                  </li>
                ))}
              </ul>
            </div>
            <div className='shows-list'>
              <ul>
                {jsonData[0].shows[count].slice(20).map((show, index) => (
                  <li key={index} className='show-item'>
                    {show}
                  </li>
                ))}
              </ul>
            </div>
          </>
        )}
      </div>
    </div>
  );
}

export default App;
```

In this code snippet, the `genre` array is used to display the list of genres. User can select their desired genre and based upon that a list of web shows available on Netflix will be displayed using the `shows` array.

Make sure to update CSS on the `App.css` file from here: [https://github.com/ayush2390/web-show-recommender/blob/main/src/App.css](https://github.com/ayush2390/web-show-recommender/blob/main/src/App.css)

and download and save this image file in main project folder: [Download Image](https://raw.githubusercontent.com/ayush2390/web-show-recommender/main/Netflix.png)

Now our project is ready!

## Result

Now, to run your project in the localhost, run this command:

```
npm run dev
```

This command will run your project on the localhost. Here is the demo of the project:

![result](assets/result.gif)

Project link - [https://github.com/ayush2390/web-show-recommender](https://github.com/ayush2390/web-show-recommender)

In this project, we used Crawlee to scrape Netflix; similarly, Crawlee can be used to scrape Single Application Pages (SPAs) and JavaScript-rendered websites. The best part is all of this can be done while coding in JavaScript/TypeScript and using a single library.

If you want to learn more about Crawlee, I recommend going through the [documentation](https://crawlee.dev/docs/quick-start) and the [Crawlee web scraping tutorial by Apify](https://blog.apify.com/crawlee-web-scraping-tutorial/).
